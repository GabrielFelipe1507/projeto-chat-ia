import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.runnables import RunnablePassthrough
from langchain_community.chat_message_histories import ChatMessageHistory
import os
from dotenv import load_dotenv
import time 

# --- IMPORTA√á√ïES PARA O AGENTE SQL (Existentes) ---
from langchain_core.tools import tool
from langchain_community.agent_toolkits import create_sql_agent
from langchain_community.utilities import SQLDatabase

# --- NOVAS IMPORTA√á√ïES (RAG/Embeddings e PDF) ---
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter 
from langchain_core.output_parsers import StrOutputParser
from langchain_huggingface import HuggingFaceEmbeddings

# Importa as fun√ß√µes do db (incluindo a db_engine)
from db import (
    db_engine, 
    listar_conversas,
    criar_nova_conversa,
    carregar_mensagens,
    salvar_mensagem,
    deletar_conversa,
    atualizar_titulo_conversa
)

# Carrega as vari√°veis de ambiente
load_dotenv()

# --- Configura√ß√£o do LLM e Embeddings ---
try:
    llm = ChatGoogleGenerativeAI(model="models/gemini-2.5-flash-preview-09-2025",
                                 google_api_key=os.getenv("GEMINI_API_KEY"),
                                 convert_system_message_to_human=True)
    
    embeddings = HuggingFaceEmbeddings(
    model_name="all-MiniLM-L6-v2"
    # Deixamos a biblioteca decidir o device (ela vai usar CPU)
    )
    print("DEBUG: Embeddings locais (HuggingFace) carregados.")
except Exception as e:
    st.error(f"Erro LLM/Embeddings: {e}")
    st.stop()

# --- 1.1 Mini-Chain para gerar t√≠tulos ---
# (Sem altera√ß√µes, continua perfeita)
try:
    prompt_titulo_template = ChatPromptTemplate.from_template(
        "Gere um t√≠tulo muito curto e descritivo (m√°ximo 5 palavras, idealmente 2-3) para uma conversa de chatbot que come√ßa com a seguinte mensagem do usu√°rio: '{primeira_mensagem}'. O t√≠tulo deve resumir o t√≥pico principal. Responda APENAS com o t√≠tulo, sem introdu√ß√µes como 'T√≠tulo:', sem aspas e sem pontua√ß√£o final."
    )
    chain_gerar_titulo = RunnablePassthrough.assign(
        primeira_mensagem=lambda x: x['input']) | prompt_titulo_template | llm
    print("DEBUG: Chain de t√≠tulo criada.")
except Exception as e:
    st.warning(f"Aviso: Chain de t√≠tulo n√£o criada: {e}")
    chain_gerar_titulo = None

# --- 2. CONFIGURA√á√ÉO DOS 3 "C√âREBROS" ---

# Fun√ß√£o para buscar o hist√≥rico DO BANCO DE DADOS (usada por todos)
def get_session_history(session_id):
    if session_id is None:
        return ChatMessageHistory()
    mensagens_do_banco = carregar_mensagens(session_id)
    history = ChatMessageHistory()
    for msg in mensagens_do_banco:
        history.add_message(msg)
    return history

# --- C√âREBRO 1: CHAT GERAL (RESTAURADO) ---
# Este √© o seu 'v4' que funcionava
try:
    prompt_template_geral = ChatPromptTemplate.from_messages(
        [
            ("system", "Voc√™ √© um assistente prestativo. Responda √†s perguntas do usu√°rio da forma mais completa e educada poss√≠vel."),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{input}"),
        ]
    )
    chain_with_memory = RunnableWithMessageHistory(
        prompt_template_geral | llm, 
        get_session_history,
        input_messages_key="input",
        history_messages_key="history",
    )
    print("DEBUG: C√©rebro 1 (Chat Geral) RESTAURADO e criado.")
except Exception as e:
    st.error(f"Erro Chain Mem√≥ria: {e}")
    st.stop()

# --- C√âREBRO 2: AGENTE DE VENDAS (SQL) ---
# (Sem altera√ß√µes, continua perfeito)
agente_sql = None
especialista_vendas = None
try:
    if db_engine is None:
        st.warning("Aviso: Engine SQLAlchemy n√£o foi criada. O 'Modo Vendas' n√£o funcionar√°.")
    else:
        db_sql = SQLDatabase(engine=db_engine, include_tables=['vendas'])
        agente_sql_executor = create_sql_agent(
            llm=llm,
            db=db_sql,
            verbose=True, 
            agent_type="tool-calling" # Corrigido com h√≠fen
        )
        
        def especialista_vendas(input_str: str): 
            print(f"DEBUG: C√©rebro 2 (Especialista Vendas) chamado com input: {input_str}")
            try:
                resultado = agente_sql_executor.invoke({"input": input_str})
                return resultado.get("output", "N√£o consegui processar a consulta SQL.")
            except Exception as e:
                print(f"ERRO no especialista_vendas: {e}")
                return f"Houve um erro ao consultar o banco de dados de vendas: {e}"
        
        print("DEBUG: C√©rebro 2 (Especialista Vendas) criado com sucesso.")

except Exception as e:
    st.error(f"ERRO CR√çTICO: N√£o foi poss√≠vel criar o Agente SQL: {e}")

# --- C√âREBRO 3: CONSULTOR DE DOCUMENTOS (RAG) ---

# A OTIMIZA√á√ÉO: @st.cache_resource
@st.cache_resource(ttl=3600) # Limpa o cache a cada 1 hora
def processar_pdf_para_rag(_file_id, file_content, file_name):
    """
    Processa o PDF anexado e RETORNA a chain RAG pronta.
    O @st.cache_resource impede que isso rode duas vezes para o mesmo arquivo.
    """
    print(f"DEBUG: Processando PDF '{file_name}' PELA PRIMEIRA VEZ (Gastando Quota de API)...")
    try:
        # Salva o arquivo temporariamente
        with open(file_name, "wb") as f:
            f.write(file_content)
        
        loader = PyPDFLoader(file_name)
        docs = loader.load()
        os.remove(file_name) # Limpa o arquivo tempor√°rio

        if not docs:
            print("Erro: N√£o foi poss√≠vel ler o conte√∫do do PDF.")
            return None

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)
        
        # ATEN√á√ÉO: √â AQUI QUE O SEU ERRO 429 (QUOTA) VAI ACONTECER (NA 1¬™ VEZ)
        vector_store = Chroma.from_documents(documents=splits, embedding=embeddings)
        
        retriever = vector_store.as_retriever()
        
        rag_prompt = ChatPromptTemplate.from_template(
            """Baseado APENAS no contexto abaixo, responda √† pergunta:
            Contexto: {contexto}
            Pergunta: {pergunta}
            Resposta:"""
        )
        
        rag_chain = (
            RunnablePassthrough.assign(contexto=(lambda x: retriever.invoke(x["pergunta"])))
            | rag_prompt
            | llm
            | StrOutputParser()
        )
        
        print(f"DEBUG: PDF '{file_name}' processado e 'chain' criada com sucesso.")
        return rag_chain
        
    except Exception as e:
        # O ERRO 429 VAI APARECER AQUI
        print(f"ERRO DETALHADO ao processar PDF: {e}")
        if os.path.exists(file_name):
            os.remove(file_name)
        # Re-lan√ßa o erro para o Streamlit mostrar
        raise e


# --- C√âREBRO 0: O ROTEADOR (NOVO) ---
try:
    roteador_prompt_template = """
    Sua tarefa √© classificar a pergunta do usu√°rio em uma de tr√™s categorias: 'SQL', 'RAG', ou 'GERAL'.

    Contexto:
    - Um PDF est√° anexado: {contexto_rag}

    Regras de Classifica√ß√£o:
    1.  Se a pergunta for sobre vendas, clientes, produtos, valores, faturamento, ou qualquer coisa da tabela 'vendas', 
        responda APENAS com a palavra: SQL
    2.  Se {contexto_rag} for True E a pergunta for sobre o documento PDF anexado (como garantias, pol√≠ticas, termos, etc.), 
        responda APENAS com a palavra: RAG
    3.  Para todo o resto (cumprimentos, piadas, conversas aleat√≥rias, ou se {contexto_rag} for False e a pergunta for sobre um PDF), 
        responda APENAS com a palavra: GERAL

    Pergunta do Usu√°rio:
    '{input}'
    """
    
    roteador_prompt = ChatPromptTemplate.from_template(roteador_prompt_template)
    chain_roteadora = roteador_prompt | llm | StrOutputParser()
    print("DEBUG: C√©rebro 0 (Roteador) criado com sucesso.")
except Exception as e:
    st.error(f"Erro ao criar o Roteador: {e}")
    st.stop()


# --- 3. CONFIGURA√á√ÉO DO FRONTEND (Streamlit) ---
st.set_page_config(page_title="Chatbot Roteador (SQL/RAG/Geral)", layout="wide")
st.title("Meu Chatbot com Gemini (Roteador Autom√°tico) üíæü§ñ")

# --- Barra Lateral (Sidebar) ---
st.sidebar.title("Minhas Conversas")

if st.sidebar.button("‚ûï Novo Chat", key="novo_chat_sidebar_button"):
    st.session_state.clear() # Limpa TUDO (ID do chat, RAG, etc)
    st.rerun()

st.sidebar.divider()

# --- CORRE√á√ÉO: UPLOADER DE VOLTA √Ä SIDEBAR (Seu Pedido) ---
uploaded_file = st.sidebar.file_uploader(
    "Anexe um PDF para fazer perguntas sobre ele", 
    type="pdf", 
    key="sidebar_uploader"
)

if uploaded_file:
    # Checa se o arquivo √© novo
    if "rag_file_name" not in st.session_state or st.session_state.rag_file_name != uploaded_file.name:
        try:
            file_id = uploaded_file.file_id
            file_content = uploaded_file.getvalue()
            file_name = uploaded_file.name
            
            # Tenta processar (s√≥ vai gastar API na 1¬™ vez)
            rag_chain = processar_pdf_para_rag(file_id, file_content, file_name)
            
            if rag_chain:
                # Salva a chain e o nome na sess√£o
                st.session_state.rag_chain = rag_chain
                st.session_state.rag_file_name = file_name
                st.sidebar.success(f"'{file_name}' processado e pronto!")
                
                # Se for um chat novo, cria ele agora
                if "conversa_ativa_id" not in st.session_state or st.session_state.conversa_ativa_id is None:
                    active_chat_id = criar_nova_conversa(titulo=f"Chat sobre {file_name}")
                    st.session_state.conversa_ativa_id = active_chat_id
                    st.rerun() # Recarrega para o novo chat aparecer
                
                # Salva uma msg no hist√≥rico do chat ATIVO
                salvar_mensagem(st.session_state.conversa_ativa_id, "ai", f"Certo! Estou pronto para responder perguntas sobre o documento '{file_name}'.")
                st.rerun() 
            else:
                st.sidebar.error("Falha ao processar o PDF.")

        except Exception as e:
            # O erro 429 vai aparecer aqui
            st.sidebar.error(f"Falha ao processar o PDF. (Erro 429?)")
elif "rag_file_name" in st.session_state:
    # Se j√° existe um PDF, mostra que ele est√° ativo
    st.sidebar.info(f"Contexto do PDF '{st.session_state.rag_file_name}' est√° ativo.")

st.sidebar.divider()
# --- FIM DO UPLOADER ---

# --- L√≥gica da Barra Lateral (Listar, Editar, Deletar) ---
try:
    lista_de_conversas = listar_conversas()
except Exception as e:
    st.sidebar.error(f"Erro ao listar conversas: {e}")
    lista_de_conversas = []
if "conversa_ativa_id" not in st.session_state:
    st.session_state.conversa_ativa_id = None
if "editing_chat_id" not in st.session_state:
    st.session_state.editing_chat_id = None

st.sidebar.markdown("**Hist√≥rico:**")
if not lista_de_conversas:
    st.sidebar.info("Nenhuma conversa ainda.")
else:
    conversations_container = st.sidebar.container(height=300)
    with conversations_container:
        for conversa in lista_de_conversas:
            conversa_id = conversa['id']
            titulo_display = conversa.get('titulo') or f'Conversa ID {conversa_id}'
            
            if st.session_state.editing_chat_id == conversa_id:
                # ... (l√≥gica de edi√ß√£o) ...
                if f"edit_input_{conversa_id}" not in st.session_state:
                    st.session_state[f"edit_input_{conversa_id}"] = None
                novo_titulo_input = st.text_input(
                    "Novo T√≠tulo:", value=titulo_display, key=f"edit_input_{conversa_id}",
                    help="Pressione Enter ou clique em Salvar"
                )
                col_salvar, col_cancelar = st.columns(2, gap="small")
                with col_salvar:
                    if st.button("Salvar", key=f"save_{conversa_id}", use_container_width=True, type="primary"):
                        if novo_titulo_input and novo_titulo_input != titulo_display:
                            if atualizar_titulo_conversa(conversa_id, novo_titulo_input):
                                st.toast("T√≠tulo atualizado!", icon="‚úÖ")
                            else:
                                st.error("Erro ao salvar o t√≠tulo.")
                        st.session_state.editing_chat_id = None
                        st.rerun()
                with col_cancelar:
                    if st.button("Cancelar", key=f"cancel_{conversa_id}", use_container_width=True):
                        st.session_state.editing_chat_id = None
                        st.rerun()
            else:
                # ... (l√≥gica de visualiza√ß√£o) ...
                col1, col2, col3 = st.columns([0.7, 0.15, 0.15], gap="small")
                with col1:
                    if st.button(titulo_display, key=f"conversa_{conversa_id}", use_container_width=True):
                        st.session_state.conversa_ativa_id = conversa_id
                        st.session_state.editing_chat_id = None
                        
                        # --- CORRE√á√ÉO: "PDF GLOBAL" (Seu Pedido) ---
                        # As linhas que limpavam o RAG foram removidas daqui.
                        # Agora o PDF persiste entre as trocas de chat.
                        
                        st.rerun()
                with col2:
                    if st.button("‚úèÔ∏è", key=f"edit_{conversa_id}", help="Renomear conversa", use_container_width=True):
                        st.session_state.editing_chat_id = conversa_id
                        st.rerun()
                with col3:
                    if st.button("üóëÔ∏è", key=f"delete_{conversa_id}", help=f"Deletar conversa {conversa_id}", use_container_width=True):
                        try:
                            if deletar_conversa(conversa_id):
                                st.toast(f"Conversa {conversa_id} deletada.", icon="‚úÖ")
                                if st.session_state.get("conversa_ativa_id") == conversa_id:
                                    st.session_state.conversa_ativa_id = None
                                time.sleep(0.5)
                                st.rerun()
                            else:
                                st.error(f"Erro ao deletar conversa {conversa_id}.")
                        except Exception as e:
                            st.error(f"Erro inesperado ao deletar: {e}")

# --- √Årea Principal ---
active_chat_id = st.session_state.get("conversa_ativa_id")

if active_chat_id:
    try:
        chat_history_para_exibir = get_session_history(active_chat_id)
        for message in chat_history_para_exibir.messages:
            role = "ai" if isinstance(message, AIMessage) else "human"
            with st.chat_message(role):
                st.markdown(message.content)
    except Exception as e:
        st.error(f"Erro ao carregar hist√≥rico para exibi√ß√£o: {e}")
else:
    if "rag_file_name" not in st.session_state:
         st.info("‚¨ÖÔ∏è Selecione uma conversa, anexe um PDF, ou digite abaixo para iniciar um novo chat.")

# --- L√ìGICA DE UPLOAD (REMOVIDA DA √ÅREA PRINCIPAL) ---

# --- INPUT √öNICO (L√ìGICA DOS 3 C√âREBROS + ROTEADOR) ---

placeholder = "Pergunte sobre vendas, o PDF anexado, ou apenas converse..."
if "rag_chain" in st.session_state:
    placeholder = f"Pergunte sobre '{st.session_state.rag_file_name}'..."
elif not active_chat_id:
    placeholder = "Digite sua primeira mensagem para iniciar um novo chat..."


if prompt := st.chat_input(placeholder, key="chat_input_principal"):

    # 1. Obter o chat_id ATUAL ou CRIAR UM NOVO
    is_new_chat = False
    if active_chat_id is None:
        try:
            novo_id = criar_nova_conversa()
            if novo_id:
                st.session_state.conversa_ativa_id = novo_id
                active_chat_id = novo_id
                is_new_chat = True
                print(f"DEBUG: Novo chat (ID:{novo_id}).")
            else:
                st.error("Falha ao criar nova conversa no banco.")
                st.stop()
        except Exception as e:
            st.error(f"Erro ao criar nova conversa: {e}")
            st.stop()

    # 2. Salvar a mensagem HUMANA
    if not salvar_mensagem(active_chat_id, "human", prompt):
        st.error("Erro ao salvar sua mensagem.")
        st.stop()
    
    # 3. Chamar o ROTEADOR (C√©rebro 0) para decidir
    response_content = ""
    try:
        rag_anexado = "rag_chain" in st.session_state
        with st.spinner("Analisando sua pergunta..."):
            categoria = chain_roteadora.invoke({
                "input": prompt,
                "contexto_rag": rag_anexado
            })
        print(f"DEBUG: Roteador decidiu -> {categoria}")

        # 4. Executar o "C√©rebro" correto com base na decis√£o
        
        # --- C√âREBRO 3 (RAG) ---
        if "RAG" in categoria:
            print(f"DEBUG: Modo RAG. Pergunta: {prompt}")
            rag_chain = st.session_state.rag_chain
            with st.spinner(f"Consultando '{st.session_state.rag_file_name}'..."):
                response_content = rag_chain.invoke({"pergunta": prompt})

        # --- C√âREBRO 2 (SQL) ---
        elif "SQL" in categoria:
            print(f"DEBUG: Modo Vendas. Pergunta: {prompt}")
            if not especialista_vendas:
                st.error("O Agente SQL n√£o est√° dispon√≠vel. Verifique os erros no terminal.")
                st.stop()
            with st.spinner("Consultando banco de dados de Vendas..."):
                response_content = especialista_vendas(prompt) # Chama a fun√ß√£o direto

        # --- C√âREBRO 1 (CHAT GERAL) ---
        else: # Categoria "GERAL"
            print(f"DEBUG: Modo Chat Geral. Pergunta: {prompt}")
            with st.spinner("Digitando..."):
                response = chain_with_memory.invoke(
                    {"input": prompt},
                    config={"configurable": {"session_id": active_chat_id}}
                )
                response_content = response.content if hasattr(response, 'content') else str(response)

        # 5. Salvar a resposta da IA
        if response_content and response_content.strip():
            if not salvar_mensagem(active_chat_id, "ai", response_content):
                st.error("Erro ao salvar a resposta da IA.")
                st.stop()
        else:
            st.warning("O LLM retornou uma resposta vazia.")

        # 6. Gerar T√≠tulo (se for novo) - L√ìGICA CORRIGIDA!
        if is_new_chat and chain_gerar_titulo:
            print("DEBUG: Novo chat, tentando gerar t√≠tulo...")
            try: # <-- O 'try' que estava causando o erro
                with st.spinner("Gerando t√≠tulo..."):
                    titulo_response = chain_gerar_titulo.invoke({"input": prompt})
                    if titulo_response and hasattr(titulo_response, 'content') and titulo_response.content.strip():
                        novo_titulo = titulo_response.content
                        print(f"DEBUG: T√≠tulo gerado: {novo_titulo}")
                        if not atualizar_titulo_conversa(active_chat_id, novo_titulo):
                            st.warning("N√£o foi poss√≠vel salvar o t√≠tulo gerado.")
                    else:
                        st.warning("LLM n√£o gerou um t√≠tulo v√°lido.")
            except Exception as e_titulo: # <-- O 'except' QUE FALTAVA
                st.warning(f"Erro ao gerar t√≠tulo: {e_titulo}")

        # 7. Recarregar a p√°gina para mostrar as mensagens salvas
        time.sleep(0.1) 
        st.rerun()

    except Exception as e:
        # O erro 429 (Quota) do Google aparecer√° aqui se o RAG for usado
        st.error(f"Erro ao processar mensagem: {e}")
        print(f"ERRO DETALHADO NO PROCESSAMENTO: {e}")