import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.runnables import RunnablePassthrough
from langchain_community.chat_message_histories import ChatMessageHistory
import os
from dotenv import load_dotenv
import time  # Para adicionar um pequeno delay e melhorar a percep√ß√£o

# Importa as fun√ß√µes do db
from db import (
    listar_conversas,
    criar_nova_conversa,
    carregar_mensagens,
    salvar_mensagem,
    deletar_conversa,
    atualizar_titulo_conversa
)

# Carrega as vari√°veis de ambiente (GEMINI_API_KEY, DB_HOST, etc.) do arquivo .env

load_dotenv()

# --- Configura√ß√£o do LLM ---
try:
    # Inicializa o modelo de chat do Google (Gemini)
    llm = ChatGoogleGenerativeAI(model="models/gemini-2.5-flash-preview-09-2025",
                                 google_api_key=os.getenv("GEMINI_API_KEY"),
                                 convert_system_message_to_human=True)
except Exception as e:
    st.error(f"Erro LLM: {e}")
    st.stop()

# --- 1.1 Mini-Chain para gerar t√≠tulos ---
# Esta √© uma "chain" (sequ√™ncia de passos) separada, s√≥ para criar t√≠tulos
try:
    # 1. Define o template do prompt: o que vamos pedir ao LLM
    prompt_titulo_template = ChatPromptTemplate.from_template(
        "Gere um t√≠tulo muito curto e descritivo (m√°ximo 5 palavras, idealmente 2-3) para uma conversa de chatbot que come√ßa com a seguinte mensagem do usu√°rio: '{primeira_mensagem}'. O t√≠tulo deve resumir o t√≥pico principal. Responda APENAS com o t√≠tulo, sem introdu√ß√µes como 'T√≠tulo:', sem aspas e sem pontua√ß√£o final."
    )
    # 2. Define a chain:
    # RunnablePassthrough.assign(...) pega o input original (que ser√° `{'input': '...'}
    # e cria uma nova chave 'primeira_mensagem' com o mesmo valor.
    # O operador | (pipe) "conecta" os passos:
    # 1. Pega o input -> 2. Passa para o prompt_titulo_template -> 3. Passa para o LLM
    chain_gerar_titulo = RunnablePassthrough.assign(
        primeira_mensagem=lambda x: x['input']) | prompt_titulo_template | llm
    print("DEBUG: Chain de t√≠tulo criada.")
except Exception as e:
    st.warning(f"Aviso: Chain de t√≠tulo n√£o criada: {e}")
    chain_gerar_titulo = None

# --- 2. CONFIGURA√á√ÉO DO BACKEND (Mem√≥ria e Chain Principal) ---

# Fun√ß√£o MODIFICADA para buscar o hist√≥rico DO BANCO DE DADOS
# Esta √© a fun√ß√£o "ponte" entre o LangChain e o nosso MySQL


def get_session_history(session_id):
    # Se n√£o h√° ID (√© um novo chat), retorna hist√≥rico vazio
    if session_id is None:
        return ChatMessageHistory()
    mensagens_do_banco = carregar_mensagens(session_id)

    # Cria um objeto ChatMessageHistory em mem√≥ria
    history = ChatMessageHistory()
    # Adiciona as mensagens carregadas (HumanMessage, AIMessage) ao objeto
    for msg in mensagens_do_banco:
        history.add_message(msg)
    return history


# Cria o template do prompt principal (para a conversa)
prompt_template = ChatPromptTemplate.from_messages(
    [
        ("system", "Voc√™ √© um assistente prestativo. Responda √†s perguntas do usu√°rio da forma mais completa e educada poss√≠vel."),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}"),
    ]
)

# Cria a "Chain" principal, agora com mem√≥ria persistente
try:
    # RunnableWithMessageHistory √© o componente m√°gico do LangChain que gerencia a mem√≥ria
    chain_with_memory = RunnableWithMessageHistory(
        prompt_template | llm,      # 1. A chain principal (Prompt + LLM)
        get_session_history,      # 2. A *fun√ß√£o* que ele deve usar para buscar/salvar o hist√≥rico
        input_messages_key="input",   # 3. O nome da vari√°vel de entrada do usu√°rio no prompt
        history_messages_key="history",  # 4. O nome da vari√°vel de hist√≥rico no prompt
    )
except Exception as e:
    st.error(f"Erro Chain Mem√≥ria: {e}")
    st.stop()

# --- 3. CONFIGURA√á√ÉO DO FRONTEND (Streamlit com Sidebar e Estado) ---
st.set_page_config(page_title="Chatbot com MySQL v4", layout="wide")
st.title("Meu Chatbot com Gemini e MySQL v4 üíæü§ñ")

# --- Barra Lateral (Sidebar) para Gerenciar Conversas ---
st.sidebar.title("Minhas Conversas")

if st.sidebar.button("‚ûï Novo Chat", key="novo_chat_sidebar_button"):
    st.session_state.conversa_ativa_id = None
    # For√ßa o recarregamento da p√°gina
    st.rerun()

# Listar conversas existentes do banco
try:
    lista_de_conversas = listar_conversas()
except Exception as e:
    st.sidebar.error(f"Erro ao listar conversas: {e}")
    lista_de_conversas = []

# st.session_state √© a "mem√≥ria RAM" do Streamlit.
# Usamos para guardar qual conversa est√° ativa e qual est√° sendo editada.

# Garante que temos um estado para a conversa ativa
if "conversa_ativa_id" not in st.session_state:
    st.session_state.conversa_ativa_id = None

# Garante que temos um estado para o "modo de edi√ß√£o"
if "editing_chat_id" not in st.session_state:
    # None significa que n√£o estamos editando nada
    st.session_state.editing_chat_id = None

st.sidebar.divider()
st.sidebar.markdown("**Hist√≥rico:**")
if not lista_de_conversas:
    st.sidebar.info("Nenhuma conversa ainda.")
else:
    conversations_container = st.sidebar.container(height=300)
    with conversations_container:
        for conversa in lista_de_conversas:
            conversa_id = conversa['id']
            titulo_display = conversa.get(
                'titulo') or f'Conversa ID {conversa_id}'
            # --- L√ìGICA DE EDI√á√ÉO ---
            # Verifica se esta conversa √© a que est√° sendo editada
            if st.session_state.editing_chat_id == conversa_id:
                # Garante que temos um estado para o input de texto
                if f"edit_input_{conversa_id}" not in st.session_state:
                    st.session_state[f"edit_input_{conversa_id}"] = None

                # Mostra o input de texto com o t√≠tulo atual
                novo_titulo_input = st.text_input(
                    "Novo T√≠tulo:",
                    value=titulo_display,
                    key=f"edit_input_{conversa_id}",
                    help="Pressione Enter ou clique em Salvar"
                )

                # Colunas para os bot√µes Salvar e Cancelar
                col_salvar, col_cancelar = st.columns(2, gap="small")

                with col_salvar:
                    if st.button("Salvar", key=f"save_{conversa_id}", use_container_width=True, type="primary"):
                        if novo_titulo_input and novo_titulo_input != titulo_display:
                            # Chama a fun√ß√£o do db.py para salvar no banco
                            if atualizar_titulo_conversa(conversa_id, novo_titulo_input):
                                st.toast("T√≠tulo atualizado!", icon="‚úÖ")
                            else:
                                st.error("Erro ao salvar o t√≠tulo.")
                        st.session_state.editing_chat_id = None  # Sai do modo de edi√ß√£o
                        st.rerun()

                with col_cancelar:
                    if st.button("Cancelar", key=f"cancel_{conversa_id}", use_container_width=True):
                        st.session_state.editing_chat_id = None  # Sai do modo de edi√ß√£o
                        st.rerun()

            else:
                # --- MODO DE VISUALIZA√á√ÉO (Normal) ---
                # Cria TR√äS colunas: T√≠tulo, Editar (‚úèÔ∏è), Deletar (üóëÔ∏è)
                col1, col2, col3 = st.columns([0.7, 0.15, 0.15], gap="small")

                with col1:
                    # Bot√£o para selecionar a conversa
                    if st.button(titulo_display, key=f"conversa_{conversa_id}", use_container_width=True):
                        st.session_state.conversa_ativa_id = conversa_id
                        # Garante que sai de qualquer outro modo de edi√ß√£o
                        st.session_state.editing_chat_id = None
                        st.rerun()

                with col2:
                    # Bot√£o de Editar ‚úèÔ∏è
                    if st.button("‚úèÔ∏è", key=f"edit_{conversa_id}", help="Renomear conversa", use_container_width=True):
                        st.session_state.editing_chat_id = conversa_id  # Entra em modo de edi√ß√£o
                        st.rerun()  # Recarrega para mostrar o input de texto

                with col3:
                    # Bot√£o de Deletar üóëÔ∏è (c√≥digo que voc√™ j√° tinha)
                    if st.button("üóëÔ∏è", key=f"delete_{conversa_id}", help=f"Deletar conversa {conversa_id}", use_container_width=True):
                        print(
                            f"DEBUG: Bot√£o DELETAR conversa {conversa_id} clicado.")
                        try:
                            if deletar_conversa(conversa_id):
                                st.toast(
                                    f"Conversa {conversa_id} deletada.", icon="‚úÖ")
                                if st.session_state.get("conversa_ativa_id") == conversa_id:
                                    st.session_state.conversa_ativa_id = None
                                time.sleep(0.5)
                                st.rerun()
                            else:
                                st.error(
                                    f"Erro ao deletar conversa {conversa_id}.")
                        except Exception as e:
                            st.error(f"Erro inesperado ao deletar: {e}")


# --- √Årea Principal ---
# Pega o ID da conversa ativa (pode ser None se for um novo chat)
active_chat_id = st.session_state.get("conversa_ativa_id")

# Exibe o hist√≥rico (SE houver chat ativo)
if active_chat_id:
    try:
        chat_history_para_exibir = get_session_history(active_chat_id)
        for message in chat_history_para_exibir.messages:
            role = "ai" if isinstance(message, AIMessage) else "human"
            with st.chat_message(role):
                st.markdown(message.content)
    except Exception as e:
        st.error(f"Erro ao carregar hist√≥rico para exibi√ß√£o: {e}")
else:
    st.info("‚¨ÖÔ∏è Selecione uma conversa na barra lateral ou digite abaixo para iniciar um novo chat.")

# --- INPUT √öNICO ---
# Define o placeholder dinamicamente
placeholder = "Digite sua mensagem..." if active_chat_id else "Digite sua primeira mensagem para iniciar um novo chat..."

if prompt := st.chat_input(placeholder, key="chat_input_principal"):

    # L√≥gica se J√Å EXISTE um chat ativo
    if active_chat_id:
        with st.chat_message("human"):
            st.markdown(prompt)
        if not salvar_mensagem(active_chat_id, "human", prompt):
            st.error("Erro ao salvar sua mensagem.")
            st.stop()
        try:
            with st.spinner("Digitando..."):
                response = chain_with_memory.invoke(
                    {"input": prompt},
                    config={"configurable": {"session_id": active_chat_id}}
                )
            if response and hasattr(response, 'content') and response.content.strip():
                if not salvar_mensagem(active_chat_id, "ai", response.content):
                    st.error("Erro ao salvar a resposta da IA.")
                st.rerun()  # Recarrega para mostrar a resposta salva
            else:
                st.warning("O LLM retornou uma resposta vazia.")
        except Exception as e:
            st.error(f"Erro ao processar mensagem: {e}")

    # L√≥gica se √© um NOVO chat
    else:
        try:
            novo_id = criar_nova_conversa()
        except Exception as e:
            st.error(f"Erro ao criar nova conversa: {e}")
            novo_id = None

        if novo_id:
            # Define como ativa ANTES de salvar/invocar
            st.session_state.conversa_ativa_id = novo_id
            print(
                f"DEBUG: Novo chat criado (ID:{novo_id}). Mensagem: {prompt}")
            if not salvar_mensagem(novo_id, "human", prompt):
                st.error("Erro ao salvar sua primeira mensagem.")
                st.stop()
            try:
                with st.spinner("Digitando..."):
                    response = chain_with_memory.invoke(
                        {"input": prompt},
                        config={"configurable": {"session_id": novo_id}}
                    )
                if response and hasattr(response, 'content') and response.content.strip():
                    if not salvar_mensagem(novo_id, "ai", response.content):
                        st.error("Erro ao salvar a primeira resposta da IA.")

                    # Tenta gerar e salvar t√≠tulo
                    if chain_gerar_titulo:
                        try:
                            with st.spinner("Gerando t√≠tulo..."):
                                titulo_response = chain_gerar_titulo.invoke(
                                    {"input": prompt})
                            if titulo_response and hasattr(titulo_response, 'content') and titulo_response.content.strip():
                                novo_titulo = titulo_response.content
                                if not atualizar_titulo_conversa(novo_id, novo_titulo):
                                    st.warning(
                                        "N√£o foi poss√≠vel salvar o t√≠tulo gerado.")
                            else:
                                st.warning("LLM n√£o gerou um t√≠tulo v√°lido.")
                        except Exception as e_titulo:
                            st.warning(f"Erro ao gerar t√≠tulo: {e_titulo}")

                    print("DEBUG: Recarregando ap√≥s novo chat.")
                    time.sleep(0.5)
                    st.rerun()  # Recarrega para mostrar tudo
                else:
                    st.warning(
                        "LLM retornou resposta vazia na primeira mensagem.")
            except Exception as e:
                st.error(f"Erro ao processar primeira mensagem: {e}")
        else:
            st.error("Falha ao criar nova conversa no banco.")
